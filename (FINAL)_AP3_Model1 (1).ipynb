{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJQHw_lPB68M",
        "outputId": "68f94555-6489-426a-a3dc-a377aa2ee4c7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9xN6Mx_Z-WgZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1716fd28-237d-439f-cf74-9aaf9e56906a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import sparse\n",
        "from sklearn import linear_model\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import operator\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import math\n",
        "from scipy.stats import norm\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m nltk.downloader punkt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIJ23ch-kp6C",
        "outputId": "d4f0af35-8a76-41ac-8224-467a91a88cbc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(filename):\n",
        "    X = []\n",
        "    Y = []\n",
        "    with open(filename, encoding=\"utf-8\") as file:\n",
        "        for line in file:\n",
        "            cols = line.split(\"\\t\")\n",
        "            idd = cols[0]\n",
        "            label = cols[2].lstrip().rstrip()\n",
        "            text = cols[3]\n",
        "\n",
        "            X.append(text)\n",
        "            Y.append(label)\n",
        "\n",
        "\n",
        "    return X, Y"
      ],
      "metadata": {
        "id": "gjhTf7SQks-q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier:\n",
        "\n",
        "    def __init__(self, feature_method, trainX, trainY, devX, devY, testX, testY):\n",
        "        self.feature_vocab = {}\n",
        "        self.feature_method = feature_method\n",
        "        self.min_feature_count=1\n",
        "        self.log_reg = None\n",
        "\n",
        "        self.trainY=trainY\n",
        "        self.devY=devY\n",
        "        self.testY=testY\n",
        "\n",
        "        self.trainX = self.process(trainX, training=True)\n",
        "        self.devX = self.process(devX, training=False)\n",
        "        self.testX = self.process(testX, training=False)\n",
        "\n",
        "    # Featurize entire dataset\n",
        "    def featurize(self, data):\n",
        "        featurized_data = []\n",
        "        for text in data:\n",
        "            feats = self.feature_method(text)\n",
        "            featurized_data.append(feats)\n",
        "        return featurized_data\n",
        "\n",
        "    # Read dataset and returned featurized representation as sparse matrix + label array\n",
        "    def process(self, X_data, training = False):\n",
        "\n",
        "        data = self.featurize(X_data)\n",
        "\n",
        "        if training:\n",
        "            fid = 0\n",
        "            feature_doc_count = Counter()\n",
        "            for feats in data:\n",
        "                for feat in feats:\n",
        "                    feature_doc_count[feat]+= 1\n",
        "\n",
        "            for feat in feature_doc_count:\n",
        "                if feature_doc_count[feat] >= self.min_feature_count:\n",
        "                    self.feature_vocab[feat] = fid\n",
        "                    fid += 1\n",
        "\n",
        "        F = len(self.feature_vocab)\n",
        "        D = len(data)\n",
        "        X = sparse.dok_matrix((D, F))\n",
        "        for idx, feats in enumerate(data):\n",
        "            for feat in feats:\n",
        "                if feat in self.feature_vocab:\n",
        "                    X[idx, self.feature_vocab[feat]] = feats[feat]\n",
        "\n",
        "        return X\n",
        "\n",
        "\n",
        "    # Train model and evaluate on held-out data\n",
        "    def train(self):\n",
        "        (D,F) = self.trainX.shape\n",
        "        best_dev_accuracy=0\n",
        "        best_model=None\n",
        "        for C in [0.1, 1, 10, 100]:\n",
        "            self.log_reg = linear_model.LogisticRegression(C = C, max_iter=10000)\n",
        "            self.log_reg.fit(self.trainX, self.trainY)\n",
        "            training_accuracy = self.log_reg.score(self.trainX, self.trainY)\n",
        "            development_accuracy = self.log_reg.score(self.devX, self.devY)\n",
        "            if development_accuracy > best_dev_accuracy:\n",
        "                best_dev_accuracy=development_accuracy\n",
        "                best_model=self.log_reg\n",
        "\n",
        "#             print(\"C: %s, Train accuracy: %.3f, Dev accuracy: %.3f\" % (C, training_accuracy, development_accuracy))\n",
        "\n",
        "        self.log_reg=best_model\n",
        "\n",
        "\n",
        "    def test(self):\n",
        "        return self.log_reg.score(self.testX, self.testY)\n",
        "\n",
        "\n",
        "    def printWeights(self, n=10):\n",
        "\n",
        "        reverse_vocab=[None]*len(self.log_reg.coef_[0])\n",
        "        for k in self.feature_vocab:\n",
        "            reverse_vocab[self.feature_vocab[k]]=k\n",
        "\n",
        "        # binary\n",
        "        if len(self.log_reg.classes_) == 2:\n",
        "              weights=self.log_reg.coef_[0]\n",
        "\n",
        "              cat=self.log_reg.classes_[1]\n",
        "              for feature, weight in list(reversed(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1))))[:n]:\n",
        "                  print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n",
        "              print()\n",
        "\n",
        "              cat=self.log_reg.classes_[0]\n",
        "              for feature, weight in list(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1)))[:n]:\n",
        "                  print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n",
        "              print()\n",
        "\n",
        "        # multiclass\n",
        "        else:\n",
        "          for i, cat in enumerate(self.log_reg.classes_):\n",
        "\n",
        "              weights=self.log_reg.coef_[i]\n",
        "\n",
        "              for feature, weight in list(reversed(sorted(zip(reverse_vocab, weights), key = operator.itemgetter(1))))[:n]:\n",
        "                  print(\"%s\\t%.3f\\t%s\" % (cat, weight, feature))\n",
        "              print()"
      ],
      "metadata": {
        "id": "XpHl2fCOkwL6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA"
      ],
      "metadata": {
        "id": "UQ-fgg4r1KAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading adjudicated data\n",
        "data = pd.read_csv('adjudicated.csv')\n",
        "data['original text'] = data['original text'].str.replace('\\t', '').str.replace('\\n', '')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-_F5vTC4Ax76",
        "outputId": "0be7acbb-9ef0-4272-a456-3da02661a38c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   data point ID  adjudicated label  \\\n",
              "0              0  adjudicated   TTA   \n",
              "1              1  adjudicated   TTA   \n",
              "2              2  adjudicated   TTA   \n",
              "3              3  adjudicated   ESH   \n",
              "4              4  adjudicated   YTA   \n",
              "\n",
              "                                       original text  \n",
              "0  my boyfriend and I live with my parents. I pay...  \n",
              "1  Hey Reddit! My original post got taken down fo...  \n",
              "2  To provide context, our daughter is 19 months ...  \n",
              "3  My husband sprung a very sudden trip on us to ...  \n",
              "4  I'm a little on the fence about this although ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e13a56b-c653-4c00-926c-884fdf6677f7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data point ID</th>\n",
              "      <th>adjudicated</th>\n",
              "      <th>label</th>\n",
              "      <th>original text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>TTA</td>\n",
              "      <td>my boyfriend and I live with my parents. I pay...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>TTA</td>\n",
              "      <td>Hey Reddit! My original post got taken down fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>TTA</td>\n",
              "      <td>To provide context, our daughter is 19 months ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>ESH</td>\n",
              "      <td>My husband sprung a very sudden trip on us to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>YTA</td>\n",
              "      <td>I'm a little on the fence about this although ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e13a56b-c653-4c00-926c-884fdf6677f7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0e13a56b-c653-4c00-926c-884fdf6677f7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0e13a56b-c653-4c00-926c-884fdf6677f7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5cbaee95-82a2-42da-b309-81bfb108afa7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5cbaee95-82a2-42da-b309-81bfb108afa7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5cbaee95-82a2-42da-b309-81bfb108afa7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"data point ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 144,\n        \"min\": 0,\n        \"max\": 499,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          361,\n          73,\n          374\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"adjudicated\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"adjudicated\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"ESH\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"original text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"I found out I had a huge brain tumor in June, had surgery in July, and I'm still recovering and have moved back in with my parents. Tumor turned out cancerous, but low grade so I'm while I'm still reeling with accepting the news, I will live and the prognosis is good. My boyfriend of 10 years has been there for me for all this - visited me at the hospital, drive me to places when I wasn't confident taking public transportation, all the acts of service. However, I feel like he acts like his life has not changed at all. He continues to get regular drinks with this friends (friends that I used to hang out too pre-tumor) every week 2-3 times a week, and when I say go out I mean come back at 2-3am, not light drinks. I'm bitter that he can he still do this, but more bitter at the fact that he still feels like doing this while I'm basically depressed at home trying to deal with the cancer. I feel he provides very little emotional support, and the fact that he is completely fine in continuing the nights out while I'm suffering has turned me so so bitter. &#x200B;&#x200B;\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_TTA = (data['label'] == 'TTA').sum()\n",
        "count_ESH = (data['label'] == 'ESH').sum()\n",
        "count_YTA = (data['label'] == 'YTA').sum()\n",
        "count_NAH = (data['label'] == 'NAH').sum()\n",
        "count_INFO = (data['label'] == 'INFO').sum()\n",
        "\n",
        "print(f\"TTA: {count_TTA}\")\n",
        "print(f\"ESH: {count_ESH}\")\n",
        "print(f\"YTA: {count_YTA}\")\n",
        "print(f\"NAH: {count_NAH}\")\n",
        "print(f\"INFO: {count_INFO}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCffVZxY1QAU",
        "outputId": "436a1b06-5daf-4a47-b84b-08ab81e23cf8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TTA: 211\n",
            "ESH: 57\n",
            "YTA: 69\n",
            "NAH: 149\n",
            "INFO: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems that, with our dataset of 500 observations, that the label TTA (they're the asshole) and NAH (no assholes here) are the most prominent, with the other labels being disproportionately dispersed throughout. Since this is logistic regression, making sure that the dataset has a balanced amount of observations per category is important for more accurate categorizations. This is a shortcoming that we could address to improve accuracy in the future. Thus, our model might be due for a method like oversampling. However, we continue on with the labeling, function-defining, and model featurization without this."
      ],
      "metadata": {
        "id": "wyf-15oG3WRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# randomizing adjudicated data\n",
        "randomized_data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "randomized_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "BbW6qdVeAycj",
        "outputId": "90959a41-c283-49e5-a7c8-190a966e6152"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     data point ID  adjudicated label  \\\n",
              "0              361  adjudicated   YTA   \n",
              "1               73  adjudicated   YTA   \n",
              "2              374  adjudicated   TTA   \n",
              "3              155  adjudicated   NAH   \n",
              "4              104  adjudicated   YTA   \n",
              "..             ...          ...   ...   \n",
              "495            106  adjudicated   NAH   \n",
              "496            270  adjudicated   YTA   \n",
              "497            348  adjudicated   TTA   \n",
              "498            435  adjudicated   TTA   \n",
              "499            102  adjudicated   YTA   \n",
              "\n",
              "                                         original text  \n",
              "0    I found out I had a huge brain tumor in June, ...  \n",
              "1    To make a long story very short, I (38M) met m...  \n",
              "2    I always wondered how people ended up in the s...  \n",
              "3    My daughter, Rachel 17, has always been a trac...  \n",
              "4    My brother (37 M), who is two years older than...  \n",
              "..                                                 ...  \n",
              "495  Here me out first as the title seems to indica...  \n",
              "496  me (f15) and my sister (f18) are, or were, ver...  \n",
              "497  My wife (27F) and I (31M) were playing Super M...  \n",
              "498  For starters, M(22) and my girlfriend F(23) ha...  \n",
              "499  So I was reprimanded by a colleague for blowin...  \n",
              "\n",
              "[500 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e95aeef-6101-47af-93f1-15cbdf8c13b9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data point ID</th>\n",
              "      <th>adjudicated</th>\n",
              "      <th>label</th>\n",
              "      <th>original text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>361</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>YTA</td>\n",
              "      <td>I found out I had a huge brain tumor in June, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>73</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>YTA</td>\n",
              "      <td>To make a long story very short, I (38M) met m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>374</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>TTA</td>\n",
              "      <td>I always wondered how people ended up in the s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>155</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>NAH</td>\n",
              "      <td>My daughter, Rachel 17, has always been a trac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>104</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>YTA</td>\n",
              "      <td>My brother (37 M), who is two years older than...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>106</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>NAH</td>\n",
              "      <td>Here me out first as the title seems to indica...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>270</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>YTA</td>\n",
              "      <td>me (f15) and my sister (f18) are, or were, ver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>348</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>TTA</td>\n",
              "      <td>My wife (27F) and I (31M) were playing Super M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>435</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>TTA</td>\n",
              "      <td>For starters, M(22) and my girlfriend F(23) ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>102</td>\n",
              "      <td>adjudicated</td>\n",
              "      <td>YTA</td>\n",
              "      <td>So I was reprimanded by a colleague for blowin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e95aeef-6101-47af-93f1-15cbdf8c13b9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8e95aeef-6101-47af-93f1-15cbdf8c13b9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8e95aeef-6101-47af-93f1-15cbdf8c13b9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-634cd4d0-d235-41fe-92df-b98928757b39\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-634cd4d0-d235-41fe-92df-b98928757b39')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-634cd4d0-d235-41fe-92df-b98928757b39 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "randomized_data",
              "summary": "{\n  \"name\": \"randomized_data\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"data point ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 144,\n        \"min\": 0,\n        \"max\": 499,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          292,\n          290,\n          288\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"adjudicated\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"adjudicated\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"TTA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"original text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"I'm a new mom. I love it. Our baby is 9 months and my SO was born to be a dad. Nothing brings us more joy.Lately we've tried to set up boundaries with my SO's parents. \\\"Don't wear perfume\\\", \\\"please speak our common language in adult conversations\\\", \\\"dont kiss the baby on the face\\\". The common language one is recent. I think my MIL stopped speaking our common language when I started finding my voice as a mother. She liked to show how I'm an outsider.Fast forward to this week. I've just had it. MIL especially always pushing me for a reaction. It's so obvious. Maybe I'm petty but she started calling the baby \\\"my baby\\\". My husband asked her not to and she just won't stop. I want to cancel Xmas with them. My FIL makes open comments about my weight and MIL doesn't respect boundaries. They do REALLY love my daughter though. AITA for canceling Xmas with my inlaws to have a quiet and enjoyable first Xmas with my SO and baby?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting data into train, test, and dev\n",
        "train_dev, test = train_test_split(randomized_data, test_size=0.2, random_state=42)\n",
        "train, dev = train_test_split(train_dev, test_size=0.25, random_state=42)\n",
        "\n",
        "print(f\"size of train: {train.shape}\")\n",
        "print(f\"size of test: {test.shape}\")\n",
        "print(f\"size of dev: {dev.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeR8BqdSA2ay",
        "outputId": "367f2986-8c8b-4ae0-e7b9-2cc2226d8034"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of train: (300, 4)\n",
            "size of test: (100, 4)\n",
            "size of dev: (100, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving train, test, and dev files as txt files ONLY RUN ONCE\n",
        "train.to_csv(\"splits/train.txt\", sep='\\t',  index=False)\n",
        "\n",
        "test.to_csv(\"splits/dev.txt\", sep='\\t', index=False)\n",
        "\n",
        "dev.to_csv(\"splits/test.txt\",  sep='\\t', index=False)"
      ],
      "metadata": {
        "id": "c8Vdv6lwA5BZ"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainingFile = \"splits/train.txt\"\n",
        "devFile = \"splits/dev.txt\"\n",
        "testFile = \"splits/test.txt\""
      ],
      "metadata": {
        "id": "BbW9c53h_JuD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(function, trainingFile, devFile, testFile):\n",
        "    trainX, trainY=load_data(trainingFile)\n",
        "    devX, devY=load_data(devFile)\n",
        "    testX, testY=load_data(testFile)\n",
        "\n",
        "    simple_classifier = Classifier(function, trainX, trainY, devX, devY, testX, testY)\n",
        "    simple_classifier.train()\n",
        "    accuracy=simple_classifier.test()\n",
        "\n",
        "    lower, upper=confidence_intervals(accuracy, len(testY), .95)\n",
        "    print(\"Test accuracy for best dev model: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy, lower, upper))\n",
        "\n",
        "    simple_classifier.printWeights()"
      ],
      "metadata": {
        "id": "1IrHPQRXBJM4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def confidence_intervals(accuracy, n, significance_level):\n",
        "    critical_value=(1-significance_level)/2\n",
        "    z_alpha=-1*norm.ppf(critical_value)\n",
        "    se=math.sqrt((accuracy*(1-accuracy))/n)\n",
        "    return accuracy-(se*z_alpha), accuracy+(se*z_alpha)"
      ],
      "metadata": {
        "id": "mufLAv7elsFg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Selection and Process"
      ],
      "metadata": {
        "id": "CAFZVVeyGXv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature 1: Binary BOW"
      ],
      "metadata": {
        "id": "QqUR2ViC6-Ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_bow_featurize(text):\n",
        "    feats = {}\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    for word in words:\n",
        "        word=word.lower()\n",
        "        feats[word]=1\n",
        "\n",
        "    return feats"
      ],
      "metadata": {
        "id": "Q5-DoYmPk1_v"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run(binary_bow_featurize, trainingFile, devFile, testFile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKlwNxDX_FOt",
        "outputId": "78f014b2-5785-4d90-dbe5-33e93cacb914"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy for best dev model: 0.416, 95% CIs: [0.320 0.512]\n",
            "\n",
            "ESH\t0.126\toff\n",
            "ESH\t0.123\tyelled\n",
            "ESH\t0.120\tmad\n",
            "ESH\t0.120\tstarted\n",
            "ESH\t0.117\thow\n",
            "ESH\t0.115\ttelling\n",
            "ESH\t0.112\tseeing\n",
            "ESH\t0.112\tonly\n",
            "ESH\t0.110\thas\n",
            "ESH\t0.108\taround\n",
            "\n",
            "INFO\t0.103\tover\n",
            "INFO\t0.102\tdoing\n",
            "INFO\t0.092\tagreed\n",
            "INFO\t0.090\ttwo\n",
            "INFO\t0.086\tbefore\n",
            "INFO\t0.077\tweeks\n",
            "INFO\t0.074\twants\n",
            "INFO\t0.074\tpretty\n",
            "INFO\t0.074\tlive\n",
            "INFO\t0.072\tyell\n",
            "\n",
            "NAH\t0.191\tsaw\n",
            "NAH\t0.178\tthese\n",
            "NAH\t0.176\tgetting\n",
            "NAH\t0.174\t've\n",
            "NAH\t0.155\tgave\n",
            "NAH\t0.146\twant\n",
            "NAH\t0.145\t's\n",
            "NAH\t0.144\tlike\n",
            "NAH\t0.133\tfind\n",
            "NAH\t0.132\tlive\n",
            "\n",
            "TTA\t0.211\teven\n",
            "TTA\t0.173\tthings\n",
            "TTA\t0.170\ttime\n",
            "TTA\t0.159\taway\n",
            "TTA\t0.159\tanother\n",
            "TTA\t0.153\thusband\n",
            "TTA\t0.138\tcame\n",
            "TTA\t0.135\tve\n",
            "TTA\t0.134\tas\n",
            "TTA\t0.126\tthrough\n",
            "\n",
            "YTA\t0.163\thad\n",
            "YTA\t0.161\there\n",
            "YTA\t0.152\tit\n",
            "YTA\t0.146\tan\n",
            "YTA\t0.142\tdone\n",
            "YTA\t0.139\tleave\n",
            "YTA\t0.138\tm\n",
            "YTA\t0.130\tsee\n",
            "YTA\t0.117\tin\n",
            "YTA\t0.115\tdo\n",
            "\n",
            "label\t0.078\toriginal\n",
            "label\t0.073\ttext\n",
            "label\t-0.000\tdignify\n",
            "label\t-0.000\tphish\n",
            "label\t-0.000\tout.\n",
            "label\t-0.000\tanymore.\n",
            "label\t-0.000\touting\n",
            "label\t-0.000\timportantly\n",
            "label\t-0.000\tanywayâ€¦upon\n",
            "label\t-0.000\tdi-\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Through this Binary BOW classification, the test accuracy is decent, though it is less than half. The issue with BOW is how the words that it is weighing could prove useful for coming up with an accurate classification, but there is no context behind the words at all, just using the sole word. With something like the AITA (Am I the Asshole?) posts, there is a lot of situational context that BOW just doesn't incorporate. Thus, we attempted to provide a bit more through Ngrams."
      ],
      "metadata": {
        "id": "304xcqhfBnYl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature 2: Ngrams"
      ],
      "metadata": {
        "id": "wX1Nql6nEg72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ngram_featurize(text, n=2):\n",
        "    feats = {}\n",
        "    words = text.split()\n",
        "    for i in range(len(words) - n + 1):\n",
        "        ngram = ' '.join(words[i:i + n])\n",
        "        feats[f'ngram_{n}_{ngram}'] = 1\n",
        "    return feats"
      ],
      "metadata": {
        "id": "lNaxmyrkEnMh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run(ngram_featurize, trainingFile, devFile, testFile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKc-sqeJEpYu",
        "outputId": "450d27b7-6479-4b7f-b642-7b851628d4f7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy for best dev model: 0.406, 95% CIs: [0.310 0.502]\n",
            "\n",
            "ESH\t0.147\tngram_2_of my\n",
            "ESH\t0.121\tngram_2_with him\n",
            "ESH\t0.117\tngram_2_and he\n",
            "ESH\t0.108\tngram_2_him to\n",
            "ESH\t0.107\tngram_2_I think\n",
            "ESH\t0.094\tngram_2_me to\n",
            "ESH\t0.086\tngram_2_this is\n",
            "ESH\t0.081\tngram_2_friends and\n",
            "ESH\t0.081\tngram_2_with her\n",
            "ESH\t0.080\tngram_2_he started\n",
            "\n",
            "INFO\t0.088\tngram_2_is that\n",
            "INFO\t0.082\tngram_2_to my\n",
            "INFO\t0.060\tngram_2_on work\n",
            "INFO\t0.059\tngram_2_yell at\n",
            "INFO\t0.059\tngram_2_to yell\n",
            "INFO\t0.059\tngram_2_Is this\n",
            "INFO\t0.058\tngram_2_so I\n",
            "INFO\t0.055\tngram_2_so she\n",
            "INFO\t0.054\tngram_2_doing this\n",
            "INFO\t0.053\tngram_2_to live\n",
            "\n",
            "NAH\t0.165\tngram_2_that I\n",
            "NAH\t0.123\tngram_2_feel like\n",
            "NAH\t0.122\tngram_2_I feel\n",
            "NAH\t0.118\tngram_2_AITA for\n",
            "NAH\t0.109\tngram_2_At the\n",
            "NAH\t0.109\tngram_2_I have\n",
            "NAH\t0.103\tngram_2_to a\n",
            "NAH\t0.103\tngram_2_want to\n",
            "NAH\t0.101\tngram_2_I did\n",
            "NAH\t0.097\tngram_2_don't want\n",
            "\n",
            "TTA\t0.186\tngram_2_was a\n",
            "TTA\t0.172\tngram_2_to be\n",
            "TTA\t0.160\tngram_2_at me\n",
            "TTA\t0.159\tngram_2_me to\n",
            "TTA\t0.158\tngram_2_I will\n",
            "TTA\t0.154\tngram_2_when she\n",
            "TTA\t0.132\tngram_2_of the\n",
            "TTA\t0.117\tngram_2_when I\n",
            "TTA\t0.112\tngram_2_and when\n",
            "TTA\t0.111\tngram_2_it was\n",
            "\n",
            "YTA\t0.166\tngram_2_and I\n",
            "YTA\t0.135\tngram_2_and asked\n",
            "YTA\t0.099\tngram_2_in my\n",
            "YTA\t0.098\tngram_2_into the\n",
            "YTA\t0.098\tngram_2_the person\n",
            "YTA\t0.094\tngram_2_I just\n",
            "YTA\t0.090\tngram_2_her to\n",
            "YTA\t0.090\tngram_2_to leave\n",
            "YTA\t0.088\tngram_2_and i\n",
            "YTA\t0.087\tngram_2_not to\n",
            "\n",
            "label\t0.450\tngram_2_original text\n",
            "label\t-0.000\tngram_2_advice everyone.\n",
            "label\t-0.000\tngram_2_the advice\n",
            "label\t-0.000\tngram_2_response. Thanks\n",
            "label\t-0.000\tngram_2_a response.\n",
            "label\t-0.000\tngram_2_dignify that\n",
            "label\t-0.000\tngram_2_or dignify\n",
            "label\t-0.000\tngram_2_a thank\n",
            "label\t-0.000\tngram_2_phish for\n",
            "label\t-0.000\tngram_2_to phish\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosing to do n-grams, we saw that accuracy did not improve, and went down from 0.416 to 0.406. From the results that display the printed weights, it demonstrates that they were given to relational text (with her, she said, to me, etc.) This could indicate good contextual information, as it can lead to assumptions on who might have initiated the conflict, or which people were responsible for which actions. However, this still lowered accuracy. We had yet to deal with sentiment in any way, which (for determining context in a heated conflict) might be important.\n",
        "\n",
        "Looking at the ngrams that were considered when n=2, there were a lot of stopwords that were considered for each category, such as \"and I\" and \"to\". Perhaps ngrams might work better with this taken into account."
      ],
      "metadata": {
        "id": "AKikMVfzGve1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature 3: NER Features"
      ],
      "metadata": {
        "id": "ZVzmqIMMTTwd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We thought, in order to give more context for the text, to incorporate Name Entity Recognition as one of the features, and use it alongside ngrams. Including information about named entities mentioned in the text, such as person names, organization names, locations, etc. can help capture important entities in the context.\n",
        "\n",
        "From our perspective, NER tagging could have helped the model in a few ways, such as providing additional semantic information about the text, which might improve the feature representation for the logistic regression model. Entities such as names of people, organizations, or locations could be indicative of the class labels in certain classification tasks. By incorporating NER tagging, the model can capture important contextual information related to named entities, which could be crucial for certain classification tasks. For example, in sentiment analysis, knowing the entities mentioned in a text might influence the sentiment expressed towards them. NER tagging could also have potentially reduced the dimensionality of the feature space by representing entities as categorical variables rather than using the entire text, which is good, sinnce a logistic regression model is categorical in nature."
      ],
      "metadata": {
        "id": "srkHI7xOoYF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the SpaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def ngram_with_ner_features(text, n=2):\n",
        "    feats = {}\n",
        "    # Generate n-gram features\n",
        "    words = text.split()\n",
        "    for i in range(len(words) - n + 1):\n",
        "        ngram = ' '.join(words[i:i + n])\n",
        "        feats[f'ngram_{n}_{ngram}'] = 1\n",
        "\n",
        "    # Perform NER tagging\n",
        "    doc = nlp(text)\n",
        "    for ent in doc.ents:\n",
        "        feats[f'ner_{ent.label_}'] = 1\n",
        "\n",
        "    return feats"
      ],
      "metadata": {
        "id": "-ibkyV0aWJFx"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run(ngram_with_ner_features, trainingFile, devFile, testFile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT8JWWhJS5lE",
        "outputId": "b0ad1269-3b56-48a5-c32a-253dac689189"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy for best dev model: 0.436, 95% CIs: [0.339 0.532]\n",
            "\n",
            "ESH\t0.147\tngram_2_of my\n",
            "ESH\t0.120\tngram_2_with him\n",
            "ESH\t0.116\tngram_2_and he\n",
            "ESH\t0.107\tngram_2_him to\n",
            "ESH\t0.105\tngram_2_I think\n",
            "ESH\t0.092\tngram_2_me to\n",
            "ESH\t0.086\tngram_2_this is\n",
            "ESH\t0.083\tner_ORDINAL\n",
            "ESH\t0.081\tngram_2_friends and\n",
            "ESH\t0.079\tngram_2_with her\n",
            "\n",
            "INFO\t0.088\tngram_2_is that\n",
            "INFO\t0.082\tngram_2_to my\n",
            "INFO\t0.060\tngram_2_on work\n",
            "INFO\t0.059\tngram_2_yell at\n",
            "INFO\t0.059\tngram_2_to yell\n",
            "INFO\t0.059\tngram_2_Is this\n",
            "INFO\t0.057\tngram_2_so I\n",
            "INFO\t0.055\tngram_2_so she\n",
            "INFO\t0.054\tngram_2_doing this\n",
            "INFO\t0.053\tngram_2_to live\n",
            "\n",
            "NAH\t0.161\tngram_2_that I\n",
            "NAH\t0.160\tner_DATE\n",
            "NAH\t0.134\tner_ORG\n",
            "NAH\t0.120\tngram_2_feel like\n",
            "NAH\t0.120\tngram_2_I feel\n",
            "NAH\t0.110\tngram_2_AITA for\n",
            "NAH\t0.107\tngram_2_At the\n",
            "NAH\t0.104\tngram_2_I have\n",
            "NAH\t0.101\tngram_2_to a\n",
            "NAH\t0.100\tngram_2_want to\n",
            "\n",
            "TTA\t0.203\tner_DATE\n",
            "TTA\t0.179\tngram_2_was a\n",
            "TTA\t0.167\tngram_2_to be\n",
            "TTA\t0.156\tngram_2_me to\n",
            "TTA\t0.155\tngram_2_at me\n",
            "TTA\t0.154\tngram_2_I will\n",
            "TTA\t0.153\tngram_2_when she\n",
            "TTA\t0.124\tner_CARDINAL\n",
            "TTA\t0.122\tngram_2_of the\n",
            "TTA\t0.115\tner_MONEY\n",
            "\n",
            "YTA\t0.175\tner_GPE\n",
            "YTA\t0.160\tngram_2_and I\n",
            "YTA\t0.134\tngram_2_and asked\n",
            "YTA\t0.100\tner_PERSON\n",
            "YTA\t0.098\tngram_2_in my\n",
            "YTA\t0.096\tngram_2_the person\n",
            "YTA\t0.096\tngram_2_into the\n",
            "YTA\t0.091\tngram_2_I just\n",
            "YTA\t0.090\tngram_2_to leave\n",
            "YTA\t0.089\tngram_2_and i\n",
            "\n",
            "label\t0.401\tngram_2_original text\n",
            "label\t-0.000\tngram_2_advice everyone.\n",
            "label\t-0.000\tngram_2_the advice\n",
            "label\t-0.000\tngram_2_response. Thanks\n",
            "label\t-0.000\tngram_2_a response.\n",
            "label\t-0.000\tngram_2_dignify that\n",
            "label\t-0.000\tngram_2_or dignify\n",
            "label\t-0.000\tngram_2_a thank\n",
            "label\t-0.000\tngram_2_phish for\n",
            "label\t-0.000\tngram_2_to phish\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mentioned above were why we thought NER tagging could help our model. Though it did improve accuracy from where we started, it still didn't improve significantly. This could be for a multitude of reasons. NER tagging algorithms might not always accurately identify entities, leading to noise in the feature space. The misclassification of entities or failure to recognize important entities could introduce errors into the model and decrease its performance. Focusing solely on named entities might have resulted in a loss of important information present in the rest of the text. If the entities themselves didn't provide sufficient discriminative information for the classification task, the model might have missed out on other relevant features. In some cases, certain entity classes might dominate the data, leading to class imbalance issues. This imbalance could affect the model's ability to generalize well to new data, especially if the minority classes are of interest.Finally, incorporating NER tagging adds complexity to the feature engineering process and model training. It requires additional preprocessing steps and might increase the computational cost of the logistic regression model, especially if the text data is large.\n",
        "\n",
        "Especially in our task, which is very subjective and different to each individual in nature, any of these factors could have lead to the feature not performing as well."
      ],
      "metadata": {
        "id": "0vA3QkUlpmSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature 4: Ngram w/ TF-IDF"
      ],
      "metadata": {
        "id": "KKgcZY_RlEnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8dgO3C_2qmog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize the TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))  # Adjust ngram_range as needed\n",
        "\n",
        "def ngram_with_tfidf_features(text):\n",
        "    feats = {}\n",
        "\n",
        "    # Generate n-gram features\n",
        "    ngrams = tfidf_vectorizer.fit_transform([text])\n",
        "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "    for i, feature in enumerate(feature_names):\n",
        "        feats[f'ngram_tfidf_{feature}'] = ngrams[0, i]\n",
        "\n",
        "    return feats"
      ],
      "metadata": {
        "id": "ZOp8u7d3Xbhm"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run(ngram_with_tfidf_features, trainingFile, devFile, testFile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bb5uQU-Ilumb",
        "outputId": "6c0341c9-d0d3-4db3-ed9d-2fd37daeb848"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy for best dev model: 0.475, 95% CIs: [0.378 0.573]\n",
            "\n",
            "ESH\t4.005\tngram_tfidf_because\n",
            "ESH\t3.757\tngram_tfidf_was\n",
            "ESH\t2.991\tngram_tfidf_we\n",
            "ESH\t2.731\tngram_tfidf_then\n",
            "ESH\t2.693\tngram_tfidf_her\n",
            "ESH\t2.567\tngram_tfidf_other\n",
            "ESH\t2.554\tngram_tfidf_up\n",
            "ESH\t2.484\tngram_tfidf_him\n",
            "ESH\t2.448\tngram_tfidf_one\n",
            "ESH\t2.382\tngram_tfidf_he\n",
            "\n",
            "INFO\t2.852\tngram_tfidf_to\n",
            "INFO\t2.618\tngram_tfidf_so\n",
            "INFO\t2.374\tngram_tfidf_mom\n",
            "INFO\t1.919\tngram_tfidf_got\n",
            "INFO\t1.848\tngram_tfidf_at\n",
            "INFO\t1.824\tngram_tfidf_donna\n",
            "INFO\t1.824\tngram_tfidf_cindy\n",
            "INFO\t1.596\tngram_tfidf_holly\n",
            "INFO\t1.582\tngram_tfidf_my mom\n",
            "INFO\t1.570\tngram_tfidf_friends\n",
            "\n",
            "NAH\t3.683\tngram_tfidf_is\n",
            "NAH\t3.479\tngram_tfidf_like\n",
            "NAH\t3.462\tngram_tfidf_no\n",
            "NAH\t3.103\tngram_tfidf_emma\n",
            "NAH\t3.056\tngram_tfidf_my parents\n",
            "NAH\t3.021\tngram_tfidf_want\n",
            "NAH\t2.845\tngram_tfidf_of\n",
            "NAH\t2.633\tngram_tfidf_was\n",
            "NAH\t2.551\tngram_tfidf_but\n",
            "NAH\t2.415\tngram_tfidf_and she\n",
            "\n",
            "TTA\t4.793\tngram_tfidf_when\n",
            "TTA\t3.936\tngram_tfidf_be\n",
            "TTA\t3.688\tngram_tfidf_money\n",
            "TTA\t3.583\tngram_tfidf_things\n",
            "TTA\t3.153\tngram_tfidf_house\n",
            "TTA\t3.046\tngram_tfidf_had\n",
            "TTA\t3.005\tngram_tfidf_could\n",
            "TTA\t2.961\tngram_tfidf_my dad\n",
            "TTA\t2.953\tngram_tfidf_when she\n",
            "TTA\t2.870\tngram_tfidf_kids\n",
            "\n",
            "YTA\t3.286\tngram_tfidf_so\n",
            "YTA\t3.140\tngram_tfidf_had\n",
            "YTA\t2.967\tngram_tfidf_leave\n",
            "YTA\t2.572\tngram_tfidf_their\n",
            "YTA\t2.491\tngram_tfidf_in\n",
            "YTA\t2.486\tngram_tfidf_it\n",
            "YTA\t2.469\tngram_tfidf_sales\n",
            "YTA\t2.410\tngram_tfidf_someone\n",
            "YTA\t2.181\tngram_tfidf_not\n",
            "YTA\t2.108\tngram_tfidf_you\n",
            "\n",
            "label\t3.324\tngram_tfidf_original text\n",
            "label\t3.322\tngram_tfidf_original\n",
            "label\t3.304\tngram_tfidf_text\n",
            "label\t-0.000\tngram_tfidf_your vacation\n",
            "label\t-0.000\tngram_tfidf_yet when\n",
            "label\t-0.000\tngram_tfidf_years so\n",
            "label\t-0.000\tngram_tfidf_worried my\n",
            "label\t-0.000\tngram_tfidf_woman someone\n",
            "label\t-0.000\tngram_tfidf_with when\n",
            "label\t-0.000\tngram_tfidf_whomever guess\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF was by-far the most successful feature that was included in our logistic regression mode. The test accuracy was the highest out of all of our tested features. We figured this could be for a couple reasons:\n",
        "\n",
        "TF-IDF assigns weights to terms based on their importance in a document relative to a corpus. This helps in capturing the significance of terms in distinguishing documents and classes. Also, by focusing on important terms and down-weighting common ones, TF-IDF naturally reduces the dimensionality of the feature space. This can help mitigate the curse of dimensionality and improve the efficiency of classification algorithms. TF-IDF features are also relatively easy to interpret, as they directly represent the importance of terms in documents. This interpretability can be useful for understanding the model's behavior and explaining its predictions.\n",
        "\n",
        "However, the model did have short-comings, with our test accuracy never reaching above 50%. It's possible that, since TF-IDF only considers the frequency of terms in documents and does not capture semantic relationships between words, this could have resulted in the model's inability to understand the meaning of text beyond individual terms. TF-IDF also ignores word-order, treating documents as bags of words, disregarding the order in which words appear. This can be problematic for tasks where word order or context is important, such as sentiment analysis or sequence labeling. The size of the vocabulary used in TF-IDF features can be large, especially with large text corpora. Managing and processing a large vocabulary can increase computational complexity and memory requirements. TF-IDF may also struggle to capture the importance of rare terms that occur infrequently in the corpus. Such terms might not receive sufficient weight even if they are highly discriminative for certain classes. TF-IDF is sensitive to stopwords, which are common words that often carry little semantic meaning (e.g., \"the\", \"and\", \"is\"). Depending on the application, stopwords may or may not be filtered out, which can impact the TF-IDF scores. The next step is to include a stopword feature.\n",
        "\n",
        "TF-IDF does not consider the contextual information of terms within documents. This limitation can affect the model's ability to capture nuanced meanings or relationships between terms."
      ],
      "metadata": {
        "id": "yr0bFUfJuTYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Load pre-trained word embeddings\n",
        "word_vectors = api.load(\"glove-wiki-gigaword-100\")\n",
        "\n",
        "def word_embedding_features(text):\n",
        "    feats = {}\n",
        "    words = text.split()\n",
        "\n",
        "    # Initialize an empty list to store word embeddings\n",
        "    embeddings = []\n",
        "\n",
        "    # Iterate over words in the text\n",
        "    for word in words:\n",
        "        # Check if the word exists in the pre-trained embeddings\n",
        "        if word in word_vectors:\n",
        "            # If the word exists, add its embedding to the list\n",
        "            embeddings.append(word_vectors[word])\n",
        "\n",
        "    # Check if there are any embeddings found\n",
        "    if embeddings:\n",
        "        # Calculate the average embedding\n",
        "        avg_embedding = np.mean(embeddings, axis=0)\n",
        "        # Add each dimension of the average embedding as a feature\n",
        "        for i, value in enumerate(avg_embedding):\n",
        "            feats[f'embedding_{i}'] = value\n",
        "\n",
        "    return feats\n",
        "\n",
        "# Example usage:\n",
        "text = \"This is an example sentence for word embedding features\"\n",
        "print(word_embedding_features(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iliH1AHrwPiI",
        "outputId": "fc334c8b-1e1a-4016-867b-e255913c766d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
            "{'embedding_0': -0.20161125, 'embedding_1': 0.3107254, 'embedding_2': 0.35212186, 'embedding_3': -0.030623376, 'embedding_4': 0.42936122, 'embedding_5': 0.39754876, 'embedding_6': -0.176708, 'embedding_7': 0.0230425, 'embedding_8': -0.12091513, 'embedding_9': 0.18468201, 'embedding_10': -0.06507763, 'embedding_11': -0.1350475, 'embedding_12': 0.112476334, 'embedding_13': 0.035186503, 'embedding_14': 0.27366638, 'embedding_15': 0.094249755, 'embedding_16': 0.25825626, 'embedding_17': -0.062186006, 'embedding_18': -0.16748899, 'embedding_19': 0.28032675, 'embedding_20': 0.029916756, 'embedding_21': -0.29419008, 'embedding_22': 0.011551003, 'embedding_23': 0.16226001, 'embedding_24': 0.37432912, 'embedding_25': 0.016816512, 'embedding_26': 0.08019963, 'embedding_27': -0.268394, 'embedding_28': -0.34400576, 'embedding_29': -0.003960747, 'embedding_30': -0.17848626, 'embedding_31': 0.5320482, 'embedding_32': -0.24195498, 'embedding_33': -0.05929875, 'embedding_34': 0.24303626, 'embedding_35': 0.25278676, 'embedding_36': 0.089439005, 'embedding_37': 0.23313248, 'embedding_38': 0.13910724, 'embedding_39': -0.20048349, 'embedding_40': -0.25514752, 'embedding_41': -0.03848662, 'embedding_42': 0.22611238, 'embedding_43': -0.102532625, 'embedding_44': 0.047823865, 'embedding_45': 0.08166, 'embedding_46': 0.31912038, 'embedding_47': -0.43480998, 'embedding_48': -0.16796272, 'embedding_49': -0.3057225, 'embedding_50': 0.2853957, 'embedding_51': -0.24081637, 'embedding_52': 0.38615677, 'embedding_53': 0.9728038, 'embedding_54': -0.5504275, 'embedding_55': -2.0448186, 'embedding_56': -0.02452, 'embedding_57': -0.43050325, 'embedding_58': 1.4571688, 'embedding_59': 0.35290998, 'embedding_60': -0.03441124, 'embedding_61': 0.4112925, 'embedding_62': -0.079955876, 'embedding_63': -0.11756475, 'embedding_64': 0.92270875, 'embedding_65': -0.2711739, 'embedding_66': 0.56040627, 'embedding_67': 0.10741289, 'embedding_68': -0.027576886, 'embedding_69': -0.046887502, 'embedding_70': -0.29572862, 'embedding_71': -0.011624135, 'embedding_72': -0.010898752, 'embedding_73': -0.1343075, 'embedding_74': 0.4371887, 'embedding_75': 0.16902588, 'embedding_76': -0.005700499, 'embedding_77': -0.046412747, 'embedding_78': -0.68915755, 'embedding_79': -0.31643492, 'embedding_80': 0.29280248, 'embedding_81': -0.38981277, 'embedding_82': -0.46966502, 'embedding_83': -0.09544662, 'embedding_84': -1.0991688, 'embedding_85': 0.19551, 'embedding_86': 0.15273324, 'embedding_87': -0.30894, 'embedding_88': 0.10530513, 'embedding_89': -0.42999908, 'embedding_90': -0.17637528, 'embedding_91': 0.009233499, 'embedding_92': -0.1298095, 'embedding_93': 0.033958994, 'embedding_94': 0.09453222, 'embedding_95': -0.31259748, 'embedding_96': -0.21019784, 'embedding_97': -0.59931624, 'embedding_98': 0.5112898, 'embedding_99': 0.17346112}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text):\n",
        "    # Here the `feats` dict should contain the features -- the key should be the feature name,\n",
        "    # and the value is the feature value.  See `simple_featurize` for an example.\n",
        "\n",
        "    feats = {}\n",
        "    # BEGIN SOLUTION\n",
        "    words = nltk.word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "    for word in filtered_words:\n",
        "      word = word.lower()\n",
        "      if word in feats.keys():\n",
        "        feats[word] += 1\n",
        "      else:\n",
        "        feats[word] = 1\n",
        "\n",
        "    # END SOLUTION\n",
        "    return feats"
      ],
      "metadata": {
        "id": "2UHxb8QxwcQd"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other features"
      ],
      "metadata": {
        "id": "pWSeBMQ4lPFB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We thought specific patterns within the text could help determine their classification. For example, sentence length: the longer the sentences in a text, it could indicate a more passionate, drawn-out, emotional response from the writer. The need to defend oneself could lead to longer sentences, which could in turn implicate someone's guilt. However, we found that this feature was not helpful. This could be due to our own interpretations of what long writing means. For some people, writing shorter could mean they feel less of a need to defend themselves, being less guilty. Others might write less and more generally because they're lying or can't back up what they're saying. The writing styles that exist in the world are so dependent on each individual person, their personalities, and their emotions as they are writing the post. Thus, this could have skewed the accuracy in the test set."
      ],
      "metadata": {
        "id": "7hK8ygMwri2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_length(text):\n",
        "    # Initialize a dictionary to store features\n",
        "    feats = {}\n",
        "\n",
        "    # Tokenize the text into sentences\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "\n",
        "    # Calculate the length of each sentence and store it as a feature\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        feats[f'sentence_length_{i+1}'] = len(sentence.split())\n",
        "\n",
        "    return feats"
      ],
      "metadata": {
        "id": "kDWTNqzpbq1t"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run(sentence_length, trainingFile, devFile, testFile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWUypsdSmOdc",
        "outputId": "0a2e52b2-1b0f-4fe6-f898-6d39399984a6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy for best dev model: 0.317, 95% CIs: [0.226 0.408]\n",
            "\n",
            "ESH\t0.818\tsentence_length_36\n",
            "ESH\t0.536\tsentence_length_35\n",
            "ESH\t0.243\tsentence_length_20\n",
            "ESH\t0.119\tsentence_length_30\n",
            "ESH\t0.044\tsentence_length_2\n",
            "ESH\t0.044\tsentence_length_13\n",
            "ESH\t0.039\tsentence_length_27\n",
            "ESH\t0.037\tsentence_length_39\n",
            "ESH\t0.031\tsentence_length_23\n",
            "ESH\t0.029\tsentence_length_21\n",
            "\n",
            "INFO\t0.485\tsentence_length_24\n",
            "INFO\t0.164\tsentence_length_17\n",
            "INFO\t0.139\tsentence_length_25\n",
            "INFO\t0.055\tsentence_length_5\n",
            "INFO\t0.033\tsentence_length_6\n",
            "INFO\t0.024\tsentence_length_18\n",
            "INFO\t0.023\tsentence_length_1\n",
            "INFO\t0.023\tsentence_length_8\n",
            "INFO\t0.020\tsentence_length_4\n",
            "INFO\t0.016\tsentence_length_9\n",
            "\n",
            "NAH\t0.513\tsentence_length_37\n",
            "NAH\t0.417\tsentence_length_34\n",
            "NAH\t0.294\tsentence_length_38\n",
            "NAH\t0.246\tsentence_length_31\n",
            "NAH\t0.132\tsentence_length_20\n",
            "NAH\t0.103\tsentence_length_29\n",
            "NAH\t0.085\tsentence_length_27\n",
            "NAH\t0.054\tsentence_length_14\n",
            "NAH\t0.045\tsentence_length_19\n",
            "NAH\t0.044\tsentence_length_21\n",
            "\n",
            "TTA\t0.182\tsentence_length_20\n",
            "TTA\t0.181\tsentence_length_32\n",
            "TTA\t0.135\tsentence_length_34\n",
            "TTA\t0.133\tsentence_length_38\n",
            "TTA\t0.117\tsentence_length_31\n",
            "TTA\t0.110\tsentence_length_43\n",
            "TTA\t0.107\tsentence_length_40\n",
            "TTA\t0.106\tsentence_length_42\n",
            "TTA\t0.087\tsentence_length_39\n",
            "TTA\t0.084\tsentence_length_47\n",
            "\n",
            "YTA\t0.535\tsentence_length_33\n",
            "YTA\t0.184\tsentence_length_20\n",
            "YTA\t0.069\tsentence_length_27\n",
            "YTA\t0.060\tsentence_length_30\n",
            "YTA\t0.050\tsentence_length_29\n",
            "YTA\t0.035\tsentence_length_2\n",
            "YTA\t0.034\tsentence_length_18\n",
            "YTA\t0.030\tsentence_length_16\n",
            "YTA\t0.029\tsentence_length_10\n",
            "YTA\t0.027\tsentence_length_13\n",
            "\n",
            "label\t0.000\tsentence_length_31\n",
            "label\t0.000\tsentence_length_35\n",
            "label\t0.000\tsentence_length_32\n",
            "label\t0.000\tsentence_length_30\n",
            "label\t0.000\tsentence_length_34\n",
            "label\t0.000\tsentence_length_33\n",
            "label\t0.000\tsentence_length_37\n",
            "label\t0.000\tsentence_length_36\n",
            "label\t0.000\tsentence_length_38\n",
            "label\t0.000\tsentence_length_39\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def combiner_function(text):\n",
        "\n",
        "    # Here the `all_feats` dict should contain the features -- the key should be the feature name,\n",
        "    # and the value is the feature value.  See `simple_featurize` for an example.\n",
        "    # at the moment, all 4 of: bag of words and your 3 original features are handed off to the combined model\n",
        "    # update the values within [bag_of_words, feature1, feature2, feature3] to change this.\n",
        "\n",
        "    all_feats={}\n",
        "    for feature in [ngram_with_tfidf_features, remove_stopwords]:\n",
        "        all_feats.update(feature(text))\n",
        "    return all_feats"
      ],
      "metadata": {
        "id": "K66WH1ajY_ms"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def print_confusion(classifier):\n",
        "    fig, ax = plt.subplots(figsize=(10,10))\n",
        "\n",
        "    # Compute the confusion matrix\n",
        "    y_pred = classifier.log_reg.predict(classifier.devX)\n",
        "    cm = confusion_matrix(classifier.devY, y_pred)\n",
        "\n",
        "    # Use ConfusionMatrixDisplay to plot\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    disp.plot(ax=ax, xticks_rotation=\"vertical\", values_format=\"d\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "dB4Mbh3XyrhH"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_final(function, trainingFile, devFile, testFile):\n",
        "    trainX, trainY=load_data(trainingFile)\n",
        "    devX, devY=load_data(devFile)\n",
        "    testX, testY=load_data(testFile)\n",
        "\n",
        "    classifier = Classifier(function, trainX, trainY, devX, devY, testX, testY)\n",
        "    classifier.train()\n",
        "    accuracy=classifier.test()\n",
        "\n",
        "    lower, upper=confidence_intervals(accuracy, len(testY), .95)\n",
        "    print(\"Test accuracy for best dev model: %.3f, 95%% CIs: [%.3f %.3f]\\n\" % (accuracy, lower, upper))\n",
        "    print_confusion(classifier)\n",
        "\n",
        "    classifier.printWeights()"
      ],
      "metadata": {
        "id": "H3RFkCnByoBt"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_final(combiner_function, trainingFile, devFile, testFile)"
      ],
      "metadata": {
        "id": "0mp_dNRVk9ob",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f021b19-3f81-4580-c00d-743eae6e64f6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy for best dev model: 0.366, 95% CIs: [0.272 0.460]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ESH\t0.373\tstarted\n",
            "ESH\t0.355\tdays\n",
            "ESH\t0.304\tfun\n",
            "ESH\t0.298\tmad\n",
            "ESH\t0.297\theadaches\n",
            "ESH\t0.293\tgives\n",
            "ESH\t0.287\tcops\n",
            "ESH\t0.276\tsounds\n",
            "ESH\t0.271\t&\n",
            "ESH\t0.271\ttrip\n",
            "\n",
            "INFO\t0.364\tmom\n",
            "INFO\t0.298\tpermission\n",
            "INFO\t0.257\tgot\n",
            "INFO\t0.215\tback\n",
            "INFO\t0.199\ttwo\n",
            "INFO\t0.195\task\n",
            "INFO\t0.192\tcause\n",
            "INFO\t0.182\teven\n",
            "INFO\t0.181\tdonna\n",
            "INFO\t0.181\tcindy\n",
            "\n",
            "NAH\t0.459\tjoke\n",
            "NAH\t0.422\tsaw\n",
            "NAH\t0.392\tlike\n",
            "NAH\t0.363\trude\n",
            "NAH\t0.358\tfeel\n",
            "NAH\t0.340\tchristmas\n",
            "NAH\t0.324\tjuices\n",
            "NAH\t0.320\talcohol\n",
            "NAH\t0.301\tspace\n",
            "NAH\t0.298\tgave\n",
            "\n",
            "TTA\t0.442\tthings\n",
            "TTA\t0.415\tn't\n",
            "TTA\t0.398\tmother\n",
            "TTA\t0.359\tstay\n",
            "TTA\t0.338\tmoney\n",
            "TTA\t0.335\taway\n",
            "TTA\t0.333\twell\n",
            "TTA\t0.329\teven\n",
            "TTA\t0.323\tmarried\n",
            "TTA\t0.304\tcould\n",
            "\n",
            "YTA\t0.386\tleave\n",
            "YTA\t0.359\tsales\n",
            "YTA\t0.306\tsasha\n",
            "YTA\t0.303\t?\n",
            "YTA\t0.295\tkid\n",
            "YTA\t0.289\tsee\n",
            "YTA\t0.286\tasked\n",
            "YTA\t0.280\tgrace\n",
            "YTA\t0.279\tsomeone\n",
            "YTA\t0.268\tperson\n",
            "\n",
            "label\t0.197\toriginal\n",
            "label\t0.192\ttext\n",
            "label\t0.114\tngram_tfidf_original text\n",
            "label\t0.114\tngram_tfidf_original\n",
            "label\t0.113\tngram_tfidf_text\n",
            "label\t-0.000\tngram_tfidf_your ride\n",
            "label\t-0.000\tngram_tfidf_your impromptu\n",
            "label\t-0.000\tngram_tfidf_you is\n",
            "label\t-0.000\tngram_tfidf_you heavily\n",
            "label\t-0.000\tngram_tfidf_you expect\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretation\n",
        "\n",
        "0 = ESH\n",
        "1 = INFO\n",
        "2 = NAH\n",
        "3 = TTA\n",
        "4 = YTA\n",
        "** 5 = label\n",
        "\n",
        "For the above confusion matrix, we can see that the two labels that were most confused were NAH and TTA, with 22 datapoints (14 + 8) being confused amongst the two. Next is ESH being confused with TTA (11). It seems that the biggest discrepancy was what to label TTA. In TTA, where the person OP is complaining about is in the wrong, it can be confused with a situation where everyone is actually in the wrong (ESH), which makes sense that it didn't predict it as well. The difference between the two boils down to the personal opinions of the annotators/adjudicator and the context of the story, which a computer just simply cannot capture. The same can be said between NAH and TTA. There is clear bias in the poster that, since they are the ones writing, they are the ones that are able to defend themselves and their actions. They have an internal bias that can transfer to their post, where they are most likely to paint themselves in a better light than how the situation might have occurred. This needs to be taken account, and though we did it in our guideline and in our annotation process, it is unclear whether a computer will be able to tell.\n",
        "\n",
        "** As mentioned in shortcomings, despite our EDA efforts, the name of our label column was incorporated into the model as a label. The reason for this is unknown but it did cost us a datapoint that might have affected our accuracy."
      ],
      "metadata": {
        "id": "bwvdN2-R5ofu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion/Reflection on Human Annotation Process\n",
        "\n",
        "In this projectâ€™s annotation guidelines, we created a detailed framework for analyzing and labeling posts from the AITA subreddit based on ethical principles and the context of the situations described. The guidelines are quite comprehensive and cover various scenarios to determine whether someone is labeled as YTA, TTA, ESH, NAH, or INFO. To summarize and reiterate the approach:\n",
        "Understanding the Conflict: Start by identifying the conflict and the parties involved (OP and the other party).\n",
        "Assessing Ethical Rules: Determine if any ethical or moral rules (like Fidelity, Reparations, Gratitude, Justice, Beneficence, Self-improvement, Non-maleficence) have been violated by either party.\n",
        "Analyzing the Aftermath: Consider how each party responds or tries to resolve the conflict. Did they attempt to fix the situation, show empathy, or understand the opposing perspective?\n",
        "Deciding Labels:\n",
        "YTA (Youâ€™re the Asshole): If the OP is clearly in the wrong based on the ethical guidelines.\n",
        "TTA (They are the Asshole): If the other party is primarily at fault.\n",
        "ESH (Everyone Sucks Here): If both parties are equally responsible or if their actions have significant consequences.\n",
        "NAH (No Assholes Here): If neither party is at fault or if their actions are justified given the circumstances.\n",
        "INFO (Didnâ€™t provide enough context): If more information is needed to make a decision.\n",
        "Considering Gray Areas: Acknowledge biases, differing moral compasses, and the severity of actions while making judgments.\n",
        "This systematic approach ensures a fair and thorough analysis of each scenario presented in the AITA posts. It requires careful consideration of the context, ethical principles, parties involved, and the aftermath of the conflict to arrive at an appropriate label for the situation. We believe these guidelines were comprehensive enough to cover most potential scenarios and we took careful consideration into addressing ambiguous situations that might arise in the data. That being said, we do want to acknowledge that subjectivity and interpretation still may have played a part in our annotation process. Annotating text for classification involves subjective judgment, as individuals may interpret scenarios differently. This subjectivity can influence the creation of guidelines and the labeling consistency across annotators. Overall, there was a pretty high level of agreement amongst the three annotators. Most of our labeling decisions were consistent, with around Â¼ of them being different. However, the adjudicator was always able to agree with one of the labels from the two annotators for each Reddit post.\n",
        "\n",
        "When we first began annotating, we had considered only using the labels YTA, NAH, and INFO. However, after reading through some of the exploration batch, we realized that these three labels were not enough to cover all the possible cases as there were many times when both parties could be assholes or the opposing party is the asshole. Therefore, we created the new labels of ESH and TTA to cover these scenarios. When reading the posts, we also began by just reading each one through from start to finish and deciding on a label after that, however we also realized that this method made it very hard to judge each post consistently. Therefore, we decided that we should define the conflict and the aftermath of each case, and use what happens in both parts of the story to process through it and decide on a label. Having a distinct conflict and aftermath also greatly helped us figure which of the parties were being assholes as we were able to decide on what makes someone an asshole based on what they do in the conflict and how they react in the aftermath. Both of these changes improved the quality and reliability of the annotated dataset. Overall, the process of reading 500 different reddit posts was relatively time-consuming as we had to think about and process each of the posts we read to decide on the label. Careful consideration was made for each labeling decision and all parties of each post were looked at and analyzed to make a final decision.\n"
      ],
      "metadata": {
        "id": "pumyaXrr9_fH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weaknesses/Shortcomings and Future Work\n",
        "\n",
        "For some possible weaknesses and shortcomings of each feature method individually, for Binary-Bagâ€“of-Words (BOW) there could be some loss of sequence information as BOW disregards the order of words and treats each document as a set of independent words. This can lead to the loss of important sequential information and context, which is crucial for understanding meaning. Also, in large vocabularies or datasets with many unique words, BOW can result in sparse matrices, making it challenging to train models effectively without overfitting or underfitting. For NGrams, while it is able to capture local word sequences, it might not generalize well to unseen combinations of words or longer contexts and may capture specific phrases or sequences that are context-dependent, leading to a lack of flexibility in representation of text. And finally for NER, relevance of named entities to the classification task is very important and extracting too many entities can possibly introduce noise into the feature set. Overall, the weaknesses and shortcomings of these feature methods show the challenges in effectively representing and understanding textual data for classification tasks. Each method has specific limitations related to its approach to text representation, context understanding, and generalization capabilities. To address these limitations, we thought it would be beneficial to combine multiple feature methods, which is what we tried to do, however these are still valid limitations overall.\n",
        "\n",
        "We chose the logistic regression model for our task as we believed it most accurately fit our project and would provide interpretable results by directly estimating the probability of a certain class given the input features. This makes it easy to understand which features contribute positively or negatively to each class prediction. Logistic regression is also computationally efficient, particularly with large sparse feature spaces common in text data. It can handle a large number of features without requiring extensive computational resources. We also explored the BERT model. However, we believe that because the number of data points was too low, this caused our BERT model to provide lower accuracy scores than logistic regression, therefore, we stuck with logistic regression as our model. Our dataset is pretty balanced. None of our labels were extremely prevalent compared to the other ones, so we donâ€™t believe this caused any issues.\n",
        "\n",
        "Another possible shortcoming is that we used accuracy alone as an evaluation metric. Exploring precision, recall, and F1-score as evaluation metrics might have allowed for a more nuanced evaluation, and helped identify areas of improvement. Precision and recall can help understand the types of errors our model is making and F1-score can help find a balance in these metrics and optimize both precision and recall simultaneously.\n",
        "\n",
        "As for future directions, some possible avenues for improvement are incorporating external knowledge sources to enhance model robustness and generalization and data augmentation and adversarial training. Integrating external knowledge graphs relevant to the task domain can provide additional contextual information. This would help improve model understanding and decision-making. Utilizing semantic embeddings derived from external sources (e.g., WordNet, ConceptNet) can also enrich feature representations and aid in capturing nuanced semantic relationships. As for data augmentation, applying synthetic data generation techniques (e.g., back-translation, paraphrasing) can increase the diversity and quantity of training data, thereby improving model generalization. Adversarial examples can be generated to train models to be robust against perturbations and adversarial attacks, enhancing model robustness and resilience.\n",
        "\n",
        "This model we developed could be leveraged in various ways to address real-world problems and applications in the future. For example, it could be used for automated content moderation on social media platforms, forums, or other online communities. It can be modified to help identify and flag inappropriate, offensive, or spammy content efficiently. This model can also be used to analyze certain types of customer feedback, such as reviews or survey responses to categorize sentiments and extract insights. In general, this text classification model can serve as a foundational component that can be adapted, enhanced, or integrated with other technologies to address specific needs and requirements.\n"
      ],
      "metadata": {
        "id": "VqUKpAHL-D9I"
      }
    }
  ]
}